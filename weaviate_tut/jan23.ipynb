{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhanu\\.conda\\envs\\idk_gpu\\lib\\site-packages\\pydantic\\_internal\\_config.py:291: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "import weaviate.classes.config as wc\n",
    "from weaviate.classes.config import Configure\n",
    "from weaviate.classes.config import ReferenceProperty\n",
    "from unstructured.partition.auto import partition\n",
    "from weaviate.util import generate_uuid5\n",
    "import re\n",
    "import requests\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "import os\n",
    "from typing import List, Dict,Tuple\n",
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from weaviate.classes import query as wvc\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from weaviate import Client\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from fpdf import FPDF\n",
    "from bs4 import BeautifulSoup\n",
    "from llama_index.readers.web import BeautifulSoupWebReader\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "from langchain.document_loaders import WebBaseLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_base = \"\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "weaviate_url = \"\"\n",
    "weaviate_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://mshwf2zhqzoe7ypcmmnfvg.c0.us-east1.gcp.weaviate.cloud/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://mshwf2zhqzoe7ypcmmnfvg.c0.us-east1.gcp.weaviate.cloud/v1/.well-known/ready \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = weaviate_url\n",
    "APIKEY = weaviate_key\n",
    "\n",
    "# Connect to your WCD instance\n",
    "client = weaviate.connect_to_wcs(\n",
    "    cluster_url=URL,\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(APIKEY),\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": openai.api_key  # Replace with your OpenAI key\n",
    "    }\n",
    ")\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://mshwf2zhqzoe7ypcmmnfvg.c0.us-east1.gcp.weaviate.cloud/v1/schema \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x1848234fdc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate.classes.config as wc\n",
    "from weaviate.classes.config import ReferenceProperty\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Demo\",\n",
    "\n",
    "    vectorizer_config=wc.Configure.Vectorizer.text2vec_openai( # specify the vectorizer and model type you're using\n",
    "        model=\"ada\",\n",
    "        model_version=\"002\",\n",
    "        type_=\"text\"\n",
    "    ),\n",
    "    generative_config=wc.Configure.Generative.openai(\n",
    "        model=\"gpt-4\"  # Optional - Defaults to `gpt-3.5-turbo`\n",
    "    ),\n",
    "\n",
    "    # Weaviate can infer schema, but it is considered best practice to define it upfront\n",
    "    properties=[\n",
    "        wc.Property(name=\"content\", data_type=wc.DataType.TEXT),\n",
    "        wc.Property(name=\"keyword\", data_type=wc.DataType.TEXT, skip_vectorization=True),\n",
    "        wc.Property(name=\"text\", data_type=wc.DataType.TEXT),\n",
    "        wc.Property(name=\"embeddings\", data_type=wc.DataType.NUMBER_ARRAY, skip_vectorization=True),\n",
    "            wc.Property(name=\"page_number\",  data_type=wc.DataType.TEXT, skip_vectorization=True),\n",
    "\n",
    "        ])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://mshwf2zhqzoe7ypcmmnfvg.c0.us-east1.gcp.weaviate.cloud/v1/meta \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grpcMaxMessageSize': 10485760,\n",
       " 'hostname': 'http://[::]:8080',\n",
       " 'modules': {'backup-gcs': {'bucketName': 'weaviate-wcs-prod-cust-us-east1-workloads-backups',\n",
       "   'rootName': '99285617-6cc7-4333-9eed-8a4232634556'},\n",
       "  'generative-anthropic': {'documentationHref': 'https://docs.anthropic.com/en/api/getting-started',\n",
       "   'name': 'Generative Search - Anthropic'},\n",
       "  'generative-anyscale': {'documentationHref': 'https://docs.anyscale.com/endpoints/overview',\n",
       "   'name': 'Generative Search - Anyscale'},\n",
       "  'generative-aws': {'documentationHref': 'https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html',\n",
       "   'name': 'Generative Search - AWS'},\n",
       "  'generative-cohere': {'documentationHref': 'https://docs.cohere.com/reference/chat',\n",
       "   'name': 'Generative Search - Cohere'},\n",
       "  'generative-databricks': {'documentationHref': 'https://docs.databricks.com/en/machine-learning/foundation-models/api-reference.html#completion-task',\n",
       "   'name': 'Generative Search - Databricks'},\n",
       "  'generative-friendliai': {'documentationHref': 'https://docs.friendli.ai/openapi/create-chat-completions',\n",
       "   'name': 'Generative Search - FriendliAI'},\n",
       "  'generative-google': {'documentationHref': 'https://cloud.google.com/vertex-ai/docs/generative-ai/chat/test-chat-prompts',\n",
       "   'name': 'Generative Search - Google'},\n",
       "  'generative-mistral': {'documentationHref': 'https://docs.mistral.ai/api/',\n",
       "   'name': 'Generative Search - Mistral'},\n",
       "  'generative-octoai': {'documentationHref': 'https://octo.ai/docs/text-gen-solution/getting-started',\n",
       "   'name': 'Generative Search - OctoAI (deprecated)'},\n",
       "  'generative-ollama': {'documentationHref': 'https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion',\n",
       "   'name': 'Generative Search - Ollama'},\n",
       "  'generative-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
       "   'name': 'Generative Search - OpenAI'},\n",
       "  'multi2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/',\n",
       "   'name': 'Cohere Module'},\n",
       "  'multi2vec-google': {'documentationHref': 'https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings',\n",
       "   'name': 'Google Multimodal Module'},\n",
       "  'multi2vec-jinaai': {'documentationHref': 'https://jina.ai/embeddings/',\n",
       "   'name': 'JinaAI CLIP Module'},\n",
       "  'multi2vec-voyageai': {'documentationHref': 'https://docs.voyageai.com/docs/multimodal-embeddings',\n",
       "   'name': 'VoyageAI Multi Modal Module'},\n",
       "  'qna-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
       "   'name': 'OpenAI Question & Answering Module'},\n",
       "  'ref2vec-centroid': {},\n",
       "  'reranker-cohere': {'documentationHref': 'https://txt.cohere.com/rerank/',\n",
       "   'name': 'Reranker - Cohere'},\n",
       "  'reranker-jinaai': {'documentationHref': 'https://jina.ai/reranker',\n",
       "   'name': 'Reranker - Jinaai'},\n",
       "  'reranker-voyageai': {'documentationHref': 'https://docs.voyageai.com/reference/reranker-api',\n",
       "   'name': 'Reranker - VoyageAI'},\n",
       "  'text2vec-aws': {'documentationHref': 'https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html',\n",
       "   'name': 'AWS Module'},\n",
       "  'text2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/',\n",
       "   'name': 'Cohere Module'},\n",
       "  'text2vec-databricks': {'documentationHref': 'https://docs.databricks.com/en/machine-learning/foundation-models/api-reference.html#embedding-task',\n",
       "   'name': 'Databricks Foundation Models Module - Embeddings'},\n",
       "  'text2vec-google': {'documentationHref': 'https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings',\n",
       "   'name': 'Google Module'},\n",
       "  'text2vec-huggingface': {'documentationHref': 'https://huggingface.co/docs/api-inference/detailed_parameters#feature-extraction-task',\n",
       "   'name': 'Hugging Face Module'},\n",
       "  'text2vec-jinaai': {'documentationHref': 'https://jina.ai/embeddings/',\n",
       "   'name': 'JinaAI Module'},\n",
       "  'text2vec-mistral': {'documentationHref': 'https://docs.mistral.ai/api/#operation/createEmbedding',\n",
       "   'name': 'Mistral Module'},\n",
       "  'text2vec-octoai': {'documentationHref': 'https://octo.ai/docs/text-gen-solution/getting-started',\n",
       "   'name': 'OctoAI Module (deprecated)'},\n",
       "  'text2vec-ollama': {'documentationHref': 'https://github.com/ollama/ollama/blob/main/docs/api.md#generate-embeddings',\n",
       "   'name': 'Ollama Module'},\n",
       "  'text2vec-openai': {'documentationHref': 'https://platform.openai.com/docs/guides/embeddings/what-are-embeddings',\n",
       "   'name': 'OpenAI Module'},\n",
       "  'text2vec-voyageai': {'documentationHref': 'https://docs.voyageai.com/docs/embeddings',\n",
       "   'name': 'VoyageAI Module'},\n",
       "  'text2vec-weaviate': {'documentationHref': 'https://api.embedding.weaviate.io',\n",
       "   'name': 'Weaviate Embedding Module'}},\n",
       " 'version': '1.28.3'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"paper_ieee.pdf\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from unstructured_ingest.connector.fsspec.s3 import S3AccessConfig, S3WriteConfig, SimpleS3Config\n",
    "from unstructured_ingest.connector.local import SimpleLocalConfig\n",
    "from unstructured_ingest.interfaces import (\n",
    "    ChunkingConfig,\n",
    "    EmbeddingConfig,\n",
    "    PartitionConfig,\n",
    "    ProcessorConfig,\n",
    "    ReadConfig,\n",
    ")\n",
    "from unstructured_ingest.runner import LocalRunner\n",
    "from unstructured_ingest.runner.writers.base_writer import Writer\n",
    "from unstructured_ingest.runner.writers.fsspec.s3 import (\n",
    "    S3Writer,\n",
    ")\n",
    "\n",
    "from unstructured_ingest.connector.local import SimpleLocalConfig\n",
    "from unstructured_ingest.connector.weaviate import (\n",
    "    SimpleWeaviateConfig,\n",
    "    WeaviateAccessConfig,\n",
    "    WeaviateWriteConfig,\n",
    ")\n",
    "from unstructured_ingest.interfaces import (\n",
    "    ChunkingConfig,\n",
    "    EmbeddingConfig,\n",
    "    PartitionConfig,\n",
    "    ProcessorConfig,\n",
    "    ReadConfig,\n",
    ")\n",
    "from unstructured_ingest.runner import LocalRunner\n",
    "from unstructured_ingest.runner.writers.base_writer import Writer\n",
    "from unstructured_ingest.runner.writers.weaviate import (\n",
    "    WeaviateWriter,\n",
    ")\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunking_config = ChunkingConfig(\n",
    "    chunk_elements=True,  # Split document into chunks\n",
    "    chunking_strategy=\"by_title\",  # Strategy for chunking\n",
    "    max_characters=8192,  # Maximum chunk size\n",
    "    combine_text_under_n_chars=1000,  # Combine small chunks\n",
    ")\n",
    "\n",
    "# Embedding Configuration\n",
    "embedding_config = EmbeddingConfig(\n",
    "    provider=\"azure-openai\",  # Using OpenAI embeddings\n",
    "    api_key= openai.api_key, # OpenAI API key\n",
    "    model=\"text-embedding-ada-002\"  # Specific embedding model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idk_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
